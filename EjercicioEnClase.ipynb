{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"dcd16efe7639ac05","cell_type":"markdown","source":"# Ejercicio 9: Uso de la API de Google Gemini\n\nEn este ejercicio vamos a aprender a utilizar la API de OpenAI\n\n## 1. Uso básico\n\nEl siguiente código sirve para conectarse con la API de Google Gemini de forma básica","metadata":{}},{"id":"41028fd9-ad0d-4c7a-bfe5-0c3fd9426cd0","cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"Gemini_API_KEY\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:33:52.097662Z","iopub.execute_input":"2026-01-07T17:33:52.098439Z","iopub.status.idle":"2026-01-07T17:33:52.160400Z","shell.execute_reply.started":"2026-01-07T17:33:52.098403Z","shell.execute_reply":"2026-01-07T17:33:52.159694Z"}},"outputs":[],"execution_count":2},{"id":"5a523a9f-1c66-4aeb-8a3c-15e59356f1a4","cell_type":"code","source":"from google import genai\n\n# 1. Configuramos el cliente usando la variable que ya tienes\nclient = genai.Client(api_key=secret_value_0)\n\n# 2. Realizamos la consulta al modelo\n# Usaremos 'gemini-2.0-flash', que es la versión más reciente y rápida\nresponse = client.models.generate_content(\n    model=\"gemini-3-flash-preview\",\n    contents=\"¿Cuál es la capital de Ecuador?\"\n)\n\n# 3. Imprimimos la respuesta\nprint(response.text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:33:54.859346Z","iopub.execute_input":"2026-01-07T17:33:54.860066Z","iopub.status.idle":"2026-01-07T17:33:59.632747Z","shell.execute_reply.started":"2026-01-07T17:33:54.860027Z","shell.execute_reply":"2026-01-07T17:33:59.631971Z"}},"outputs":[{"name":"stderr","text":"Warning: there are non-text parts in the response: ['thought_signature'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"La capital de Ecuador es **Quito**.\n","output_type":"stream"}],"execution_count":4},{"id":"3a30de61bd443d1d","cell_type":"markdown","source":"## 2. Retrieval","metadata":{}},{"id":"5488be80d85df276","cell_type":"markdown","source":"### 2.1 Cargo el corpus de 20 News Groups","metadata":{}},{"id":"36aa2a96f75e4a43","cell_type":"code","source":"from sklearn.datasets import fetch_20newsgroups\n\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\nnewsgroupsdocs = newsgroups.data","metadata":{"ExecuteTime":{"end_time":"2025-06-30T15:14:54.799009Z","start_time":"2025-06-30T15:14:47.902617Z"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:34:03.322611Z","iopub.execute_input":"2026-01-07T17:34:03.322897Z","iopub.status.idle":"2026-01-07T17:34:15.485148Z","shell.execute_reply.started":"2026-01-07T17:34:03.322874Z","shell.execute_reply":"2026-01-07T17:34:15.484552Z"}},"outputs":[],"execution_count":5},{"id":"d58edae5-069d-4d8a-9909-6dd5ed5336f8","cell_type":"code","source":"import pandas as pd\n\ndf = pd.DataFrame(newsgroupsdocs, columns=['text'])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:34:18.780295Z","iopub.execute_input":"2026-01-07T17:34:18.781234Z","iopub.status.idle":"2026-01-07T17:34:18.820104Z","shell.execute_reply.started":"2026-01-07T17:34:18.781204Z","shell.execute_reply":"2026-01-07T17:34:18.819406Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                    text\n0      \\n\\nI am sure some bashers of Pens fans are pr...\n1      My brother is in the market for a high-perform...\n2      \\n\\n\\n\\n\\tFinally you said what you dream abou...\n3      \\nThink!\\n\\nIt's the SCSI card doing the DMA t...\n4      1)    I have an old Jasmine drive which I cann...\n...                                                  ...\n18841  DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n18842  \\nNot in isolated ground recepticles (usually ...\n18843  I just installed a DX2-66 CPU in a clone mothe...\n18844  \\nWouldn't this require a hyper-sphere.  In 3-...\n18845  After a tip from Gary Crum (crum@fcom.cc.utah....\n\n[18846 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>My brother is in the market for a high-perform...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1)    I have an old Jasmine drive which I cann...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>18841</th>\n      <td>DN&gt; From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...</td>\n    </tr>\n    <tr>\n      <th>18842</th>\n      <td>\\nNot in isolated ground recepticles (usually ...</td>\n    </tr>\n    <tr>\n      <th>18843</th>\n      <td>I just installed a DX2-66 CPU in a clone mothe...</td>\n    </tr>\n    <tr>\n      <th>18844</th>\n      <td>\\nWouldn't this require a hyper-sphere.  In 3-...</td>\n    </tr>\n    <tr>\n      <th>18845</th>\n      <td>After a tip from Gary Crum (crum@fcom.cc.utah....</td>\n    </tr>\n  </tbody>\n</table>\n<p>18846 rows × 1 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"id":"16237cc6ae2f7853","cell_type":"markdown","source":"### 2.2 Transformo a embeddings","metadata":{}},{"id":"f8b271aa4b20ace0","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\n\n# Eliminar filas sin texto\ndf = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n\ndef normalize_text(s: str) -> str:\n    s = str(s)\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s\n\n# Aplicamos la normalización\ndf[\"text_norm\"] = df[\"text\"].map(normalize_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:34:22.330310Z","iopub.execute_input":"2026-01-07T17:34:22.330925Z","iopub.status.idle":"2026-01-07T17:34:23.696319Z","shell.execute_reply.started":"2026-01-07T17:34:22.330896Z","shell.execute_reply":"2026-01-07T17:34:23.695733Z"}},"outputs":[],"execution_count":7},{"id":"e0c04946-800e-4e48-ba8a-03431bbd9f79","cell_type":"code","source":"def chunk_text(text: str, max_chars: int = 800, overlap: int = 100):\n    chunks = []\n    start = 0\n    n = len(text)\n    while start < n:\n        end = min(start + max_chars, n)\n        chunk = text[start:end].strip()\n        if len(chunk) > 0:\n            chunks.append(chunk)\n        if end == n:\n            break\n        start = max(0, end - overlap)\n    return chunks\n\n# Generamos la nueva tabla de chunks\nrecords = []\nfor i, row in tqdm(df.iterrows(), total=len(df), desc=\"Fragmentando textos\"):\n    chunks = chunk_text(row[\"text_norm\"], max_chars=800, overlap=100)\n    for j, ch in enumerate(chunks):\n        records.append({\n            \"doc_id\": i,\n            \"chunk_id\": j,\n            \"text\": ch\n        })\n\nchunks_df = pd.DataFrame(records)\nprint(f\"Total de chunks generados: {len(chunks_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:34:29.184728Z","iopub.execute_input":"2026-01-07T17:34:29.185318Z","iopub.status.idle":"2026-01-07T17:34:30.032527Z","shell.execute_reply.started":"2026-01-07T17:34:29.185288Z","shell.execute_reply":"2026-01-07T17:34:30.031871Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Fragmentando textos:   0%|          | 0/18846 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"517366430dc84f6486123c3fcb3755db"}},"metadata":{}},{"name":"stdout","text":"Total de chunks generados: 38871\n","output_type":"stream"}],"execution_count":8},{"id":"516aed47-f1c9-41d2-974d-35a222207d7a","cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\n# Cargamos el modelo (Kaggle lo descargará automáticamente)\nMODEL_NAME = \"intfloat/e5-base-v2\"\nmodel = SentenceTransformer(MODEL_NAME)\n\n# Preparar los textos con el prefijo obligatorio para E5\npassages = [\"passage: \" + t for t in chunks_df[\"text\"].tolist()]\n\n# Generar embeddings\n# Si activaste la GPU, esto será muy rápido\nembeddings = model.encode(\n    passages,\n    batch_size=64,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n).astype(\"float32\")\n\nprint(\"Matriz de embeddings creada con éxito:\", embeddings.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:34:40.688114Z","iopub.execute_input":"2026-01-07T17:34:40.688398Z","iopub.status.idle":"2026-01-07T17:47:40.028603Z","shell.execute_reply.started":"2026-01-07T17:34:40.688374Z","shell.execute_reply":"2026-01-07T17:47:40.027869Z"}},"outputs":[{"name":"stderr","text":"2026-01-07 17:34:54.281281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767807294.507897      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767807294.578857      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767807295.130589      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767807295.130630      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767807295.130633      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767807295.130636      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad9f46e189144f7291646e157c124238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75447c4d83ea4f89a700617d73230c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdd83ebe4ebe4e79aabd2c41af580609"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a3a9f4835874be394a28bdc439f58a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b019f35efcb434baf1b0a876fba0219"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2f3f2041ac54826bc738c5ea77ef6d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"758e793fd73f4d66a2a2674abab4b355"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2c763b787624e6fa5ef7c0aeef51980"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee5a5fec8f6f41308129a28bceeaec27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40dbf2df494044fb91a855f54ecd480f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/608 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4daed71c3394932960205cd8e70c595"}},"metadata":{}},{"name":"stdout","text":"Matriz de embeddings creada con éxito: (38871, 768)\n","output_type":"stream"}],"execution_count":9},{"id":"939af4d8947ba81","cell_type":"markdown","source":"### 2.3 Creo una query y hago la búsqueda","metadata":{}},{"id":"9da75a5ce3c09aec","cell_type":"code","source":"def embed_query(query: str) -> np.ndarray:\n    # E5 requiere el prefijo 'query: ' para la búsqueda\n    q = \"query: \" + query\n    vec = model.encode(\n        [q],\n        convert_to_numpy=True,\n        normalize_embeddings=True\n    ).astype(\"float32\")\n    return vec\n\n# Ejemplo de uso:\npregunta_vector = embed_query(\"Machine learning\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:49:02.766898Z","iopub.execute_input":"2026-01-07T17:49:02.767241Z","iopub.status.idle":"2026-01-07T17:49:02.786468Z","shell.execute_reply.started":"2026-01-07T17:49:02.767213Z","shell.execute_reply":"2026-01-07T17:49:02.785887Z"}},"outputs":[],"execution_count":15},{"id":"b5fe739b-ef82-4660-80b8-e21a407693a2","cell_type":"code","source":"!pip -q install faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:49:40.872914Z","iopub.execute_input":"2026-01-07T17:49:40.873502Z","iopub.status.idle":"2026-01-07T17:49:46.946876Z","shell.execute_reply.started":"2026-01-07T17:49:40.873471Z","shell.execute_reply":"2026-01-07T17:49:46.946158Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":17},{"id":"f40a3cf8-4c90-41ef-8787-d9f4452681f7","cell_type":"code","source":"# código base para FAISS\nimport faiss\nimport numpy as np\n\n# Asumiendo `embeddings` en un array NxD\nindex = faiss.IndexFlatL2(embeddings.shape[1])\nindex.add(embeddings)\n\nD, I = index.search(pregunta_vector, k=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T17:50:21.633876Z","iopub.execute_input":"2026-01-07T17:50:21.634381Z","iopub.status.idle":"2026-01-07T17:50:21.753912Z","shell.execute_reply.started":"2026-01-07T17:50:21.634349Z","shell.execute_reply":"2026-01-07T17:50:21.753095Z"}},"outputs":[],"execution_count":21},{"id":"15ca8e31-5dc3-4814-8b2c-7cad33e35165","cell_type":"code","source":"print(I[0][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T18:00:11.272267Z","iopub.execute_input":"2026-01-07T18:00:11.272583Z","iopub.status.idle":"2026-01-07T18:00:11.277142Z","shell.execute_reply.started":"2026-01-07T18:00:11.272533Z","shell.execute_reply":"2026-01-07T18:00:11.276593Z"}},"outputs":[{"name":"stdout","text":"25443\n","output_type":"stream"}],"execution_count":26},{"id":"ba3649d5-21d2-4cf6-8edb-5b4fdfa0db00","cell_type":"code","source":"passages[I[0][0]]\n#obtener los 10 passages\n# se le manda al llm una query donde se muestra el ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-07T18:04:18.667858Z","iopub.execute_input":"2026-01-07T18:04:18.668442Z","iopub.status.idle":"2026-01-07T18:04:18.672745Z","shell.execute_reply.started":"2026-01-07T18:04:18.668413Z","shell.execute_reply":"2026-01-07T18:04:18.672042Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"\"passage: software around. Hopefully I'll be able to provide more information in a future version of this posting. richard welty (welty@balltown.cma.com)\""},"metadata":{}}],"execution_count":39},{"id":"d6b0a8f32632e705","cell_type":"markdown","source":"Obtengo los 5 documentos más similares a mi query","metadata":{}},{"id":"e0f02ff1b75a2864","cell_type":"code","source":"def get_top_k_indices(query_vec, corpus_embeddings, k=5):\n    # Calculamos la similitud (Producto punto es igual a similitud coseno si están normalizados)\n    # query_vec tiene forma (1, 768), corpus_embeddings tiene forma (N, 768)\n    similarities = np.dot(corpus_embeddings, query_vec.T).flatten()\n    \n    # Obtenemos los índices de los 'k' valores más altos\n    top_k_indices = np.argsort(similarities)[-k:][::-1]\n    \n    return top_k_indices, similarities[top_k_indices]","metadata":{},"outputs":[],"execution_count":null},{"id":"6dc2a16ecdab7c0c","cell_type":"code","source":"def responder_con_rag(pregunta, k=5):\n    # 1. Convertir la pregunta en vector\n    query_vec = embed_query(pregunta)\n    \n    # 2. Buscar los 5 fragmentos más parecidos\n    indices, scores = get_top_k_indices(query_vec, embeddings, k=k)\n    \n    # 3. Recuperar los textos de esos índices\n    contextos_recuperados = chunks_df.iloc[indices][\"text\"].tolist()\n    \n    # 4. Construir el Prompt para Gemini\n    # Unimos los fragmentos en un solo bloque de texto\n    contexto_unido = \"\\n---\\n\".join(contextos_recuperados)\n    \n    prompt_final = f\"\"\"\n    Eres un asistente experto. Utiliza la siguiente información (CONTEXTO) para responder la PREGUNTA del usuario.\n    Si la respuesta no está en el contexto, di que no lo sabes, no inventes información.\n\n    CONTEXTO:\n    {contexto_unido}\n\n    PREGUNTA:\n    {pregunta}\n    \n    RESPUESTA:\n    \"\"\"\n\n    # 5. Llamada a la API de Gemini\n    response = client.models.generate_content(\n        model=\"gemini-3-flash-preview\",\n        contents=prompt_final\n    )\n    \n    return response.text, contextos_recuperados\n\n\nmi_pregunta = \"¿Qué funciones cumple un indicador de batería?\"\nrespuesta, fuentes = responder_con_rag(mi_pregunta)\n\nprint(\"=== RESPUESTA DE GEMINI ===\")\nprint(respuesta)\nprint(\"\\n=== FUENTES UTILIZADAS (TOP 1) ===\")\nprint(fuentes[0])","metadata":{},"outputs":[],"execution_count":null}]}