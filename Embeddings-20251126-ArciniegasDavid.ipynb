{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"d3f8b5c16e7eb563","cell_type":"markdown","source":"# Ejercicio 6: Dense Retrieval e Introducción a FAISS\n\n## Objetivo de la práctica\n\nGenerar embeddings con sentence-transformers (SBERT, E5), e indexar documentos con FAISS ","metadata":{}},{"id":"cb94bd31-f6fe-40e3-9d75-8edab46540bf","cell_type":"code","source":"!pip install sentence-transformers faiss-cpu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T17:32:16.631128Z","iopub.execute_input":"2025-11-26T17:32:16.633580Z","iopub.status.idle":"2025-11-26T17:32:21.258319Z","shell.execute_reply.started":"2025-11-26T17:32:16.633532Z","shell.execute_reply":"2025-11-26T17:32:21.256896Z"},"scrolled":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\nRequirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.13.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.36.0)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\nRequirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.15.0)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.10.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.10.5)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\n","output_type":"stream"}],"execution_count":15},{"id":"cdd69ed7fcbeef9d","cell_type":"markdown","source":"## Parte 1: Carga del Corpus\n### Actividad\n\n1. Carga el corpus 20 Newsgroups desde sklearn.datasets.fetch_20newsgroups.\n2. Limita el corpus a los primeros 2000 documentos para facilitar el procesamiento.","metadata":{}},{"id":"b00fbde6cfc88b","cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import fetch_20newsgroups\nfrom sentence_transformers import SentenceTransformer\nimport faiss\n\nnewsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n\ndocuments = newsgroups.data[:2000]\n\nprint(f\"Cantidad de documentos cargados: {len(documents)}\")\nprint(\"Ejemplo de documento:\\n\", documents[0][:200])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T17:32:21.260555Z","iopub.execute_input":"2025-11-26T17:32:21.261658Z","iopub.status.idle":"2025-11-26T17:32:23.384217Z","shell.execute_reply.started":"2025-11-26T17:32:21.261622Z","shell.execute_reply":"2025-11-26T17:32:23.383115Z"}},"outputs":[{"name":"stdout","text":"Cantidad de documentos cargados: 2000\nEjemplo de documento:\n \n\nI am sure some bashers of Pens fans are pretty confused about the lack\nof any kind of posts about the recent Pens massacre of the Devils. Actually,\nI am  bit puzzled too and a bit relieved. However,\n","output_type":"stream"}],"execution_count":16},{"id":"b9184f4b3e66e20a","cell_type":"markdown","source":"## Parte 2: Generación de Embeddings\n### Actividad\n\n1. Usa dos modelos de sentence-transformers. Puedes usar: `'all-MiniLM-L6-v2'` (SBERT), o `'intfloat/e5-base'` (E5). Cuando uses E5, antepon `\"passage: \"` a cada documento antes de codificar.\n2. Genera los vectores de embeddings para todos los documentos usando el modelo seleccionado.\n3. Guarda los embeddings en un array de NumPy para su posterior indexación.","metadata":{}},{"id":"525ae7515c6169d9","cell_type":"code","source":"model_name = 'all-MiniLM-L6-v2' \n# model_name = 'intfloat/e5-base'  # usar E5\n\nprint(f\"Cargando modelo: {model_name}...\")\nmodel = SentenceTransformer(model_name)\n\nif 'e5' in model_name:\n    docs_to_encode = [\"passage: \" + doc for doc in documents]\nelse:\n    docs_to_encode = documents\n    \nprint(\"Generando embeddings\")\nembeddings = model.encode(docs_to_encode, show_progress_bar=True)\n\nembeddings = np.array(embeddings).astype('float32')\n\nprint(f\"Dimensiones: {embeddings.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T17:32:23.385494Z","iopub.execute_input":"2025-11-26T17:32:23.385874Z","iopub.status.idle":"2025-11-26T17:33:55.667757Z","shell.execute_reply.started":"2025-11-26T17:32:23.385837Z","shell.execute_reply":"2025-11-26T17:33:55.665902Z"}},"outputs":[{"name":"stdout","text":"Cargando modelo: all-MiniLM-L6-v2...\nGenerando embeddings\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/63 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"351a1d6979654f188952dea0e4ad6927"}},"metadata":{}},{"name":"stdout","text":"Dimensiones: (2000, 384)\n","output_type":"stream"}],"execution_count":17},{"id":"40462a067ca2d379","cell_type":"markdown","source":"## Parte 3: Consulta\n### Actividad\n\n1. Escribe una consulta en lenguaje natural. Ejemplos:\n\n    * \"God, religion, and spirituality\"\n    * \"space exploration\"\n    * \"car maintenance\"\n\n2. Codifica la consulta utilizando el mismo modelo de embeddings. Cuando uses E5, antepon `\"query: \"` a la consulta.\n3. Recupera los 5 documentos más relevantes con similitud coseno.\n4. Muestra los textos de los documentos recuperados (puedes mostrar solo los primeros 500 caracteres de cada uno).","metadata":{}},{"id":"aad085806124c709","cell_type":"code","source":"\nfaiss.normalize_L2(embeddings)\n\ndimension = embeddings.shape[1]\nindex = faiss.IndexFlatIP(dimension)\nindex.add(embeddings)\n\nquery_text = \"Stanislav petrov\" \n\nprint(f\"\\nConsulta: '{query_text}'\")\n\nif 'e5' in model_name:\n    query_input = \"query: \" + query_text\nelse:\n    query_input = query_text\n\nquery_vector = model.encode([query_input])\n\nfaiss.normalize_L2(query_vector)\n\nk = 5\nD, I = index.search(query_vector, k) \n\nfor i in range(k):\n    doc_id = I[0][i]\n    score = D[0][i]\n    print(f\"\\nResultado {i+1} (Score: {score:.4f}):\")\n    print(documents[doc_id][:500])\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-26T17:33:55.669961Z","iopub.execute_input":"2025-11-26T17:33:55.670304Z","iopub.status.idle":"2025-11-26T17:33:55.707617Z","shell.execute_reply.started":"2025-11-26T17:33:55.670278Z","shell.execute_reply":"2025-11-26T17:33:55.706279Z"}},"outputs":[{"name":"stdout","text":"\nConsulta: 'Stanislav petrov'\n\nResultado 1 (Score: 0.3612):\n\nI saw Messier and Leetch shooting at a camera on Letterman(?).  I\ncould have been any show though, since I watch NONE of those late\nnight shows very regularly.\n\t\t\t\t\t-John Santore\n\nPhiladelphia Flyers in '93-'94! \n\n=============================================================================\n ____________________                                \n/                    \\                   \"We break the surface tension \n\\_________     ____   \\                   with our wild kinetic dreams\"\n/        \n\nResultado 2 (Score: 0.3397):\n\nThat was Clint Malarchuk.  That was a very dangerous accident.  He could he\ndied right there on the ice.  However, he has played since  \nbut I don't know where he is now.  I think he is still playing but I'm\nnot positive.  He was a Sabre at the time.\nI don't know who skated into him though.\n\n\nI remember a couple of seasons before the Malarchuk incident Borje\nSalming of Toronto fell down in the crease and someone skated into\nhis face.  That took a lot of stiches to fix.\n\n\nResultado 3 (Score: 0.3359):\nMark Ira Kaufman writes\n\nResultado 4 (Score: 0.3155):\nDear Ulf,\n\n\tWould you possibly consider helpiMontreal Canadiens fans everywhere\nby throwing a knee-check in the direction of Denis Savard during your upcoming\ngame against Montreal? We just can't seem to win WITH him!\n\n\t\t\t\t\t\tThanx alot,\n\t\t\t\t\t\tPete H.\n\n\n:-)\n\n\nResultado 5 (Score: 0.3129):\n\n    I'm sick too watching all-american names like GRETZKY etc.\n\n    Which names you accept ? Sitting bull and dances with wolves ?\n\n    It is North America. What are you doing here ?\n\n","output_type":"stream"}],"execution_count":18}]}