{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8172,"sourceType":"datasetVersion","datasetId":1442}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/davidarciniegas16/proyecto-ri-vinos-arciniegas-quirola?scriptVersionId=284698748\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:13:31.629223Z","iopub.execute_input":"2025-11-23T16:13:31.62957Z","iopub.status.idle":"2025-11-23T16:13:32.016469Z","shell.execute_reply.started":"2025-11-23T16:13:31.629544Z","shell.execute_reply":"2025-11-23T16:13:32.015479Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/wine-reviews/winemag-data-130k-v2.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:13:39.655644Z","iopub.execute_input":"2025-11-23T16:13:39.656058Z","iopub.status.idle":"2025-11-23T16:13:41.73521Z","shell.execute_reply.started":"2025-11-23T16:13:39.656036Z","shell.execute_reply":"2025-11-23T16:13:41.734215Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dependencias","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport string\nimport math\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import SnowballStemmer\nfrom collections import defaultdict\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# Descargar recursos necesarios de NLTK\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('punkt_tab')\n\n# Configuración global\nSTOPWORDS = set(stopwords.words('english'))\nSTEMMER = SnowballStemmer('english')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:13:46.208027Z","iopub.execute_input":"2025-11-23T16:13:46.208371Z","iopub.status.idle":"2025-11-23T16:13:48.038221Z","shell.execute_reply.started":"2025-11-23T16:13:46.208346Z","shell.execute_reply":"2025-11-23T16:13:48.037157Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 1. Preprocesamiento y Construcción del Corpus ###\n### Funcion para normalizar el texto realizar tokenización, minúsculas, eliminación de stopwords y stemming.","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    # Convertir a minúsculas\n    text = text.lower()\n    \n    # Eliminar puntuación\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # Tokenización\n    tokens = word_tokenize(text)\n    \n    # Stopwords y Stemming\n    clean_tokens = [\n        STEMMER.stem(token) \n        for token in tokens \n        if token not in STOPWORDS and token.isalpha()\n    ]\n    \n    return clean_tokens\n\n# Carga y preparación del dataset\n# Asumimos que el DataFrame 'df' ya está cargado como mostraste en tu imagen\n# Usaremos un subconjunto para pruebas rápidas, pero el código escala.\n\ndf = df.dropna(subset=['description']).reset_index(drop=True)\n# df = df.sample(10000, random_state=42).reset_index(drop=True) # Descomentar para pruebas rápidas\n\nprint(f\"Procesando {len(df)} documentos...\")\n\n# Aplicamos preprocesamiento (puede tardar unos minutos en 130k filas)\ndf['tokens'] = df['description'].apply(preprocess_text)\n\n# Creamos una columna de texto unido para los modelos vectoriales de scikit-learn\ndf['processed_text'] = df['tokens'].apply(lambda x: ' '.join(x))\n\nprint(\"Preprocesamiento completado.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:14:05.255181Z","iopub.execute_input":"2025-11-23T16:14:05.255759Z","iopub.status.idle":"2025-11-23T16:15:08.428723Z","shell.execute_reply.started":"2025-11-23T16:14:05.255726Z","shell.execute_reply":"2025-11-23T16:15:08.427507Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 2. Indexación (Índice Invertido) ###","metadata":{}},{"cell_type":"code","source":"def build_inverted_index(df_tokens):\n    inverted_index = defaultdict(list)\n    \n    for doc_id, tokens in enumerate(df_tokens):\n        # Contar frecuencia de términos en el documento actual\n        term_freq = defaultdict(int)\n        for token in tokens:\n            term_freq[token] += 1\n            \n        # Actualizar índice invertido\n        for token, freq in term_freq.items():\n            inverted_index[token].append((doc_id, freq))\n            \n    return inverted_index\n\n# Construcción del índice\ninverted_index = build_inverted_index(df['tokens'])\nprint(f\"Índice construido con {len(inverted_index)} términos únicos.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:15:26.738156Z","iopub.execute_input":"2025-11-23T16:15:26.738557Z","iopub.status.idle":"2025-11-23T16:15:29.006446Z","shell.execute_reply.started":"2025-11-23T16:15:26.73853Z","shell.execute_reply":"2025-11-23T16:15:29.005308Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Modelos de Recuperación","metadata":{}},{"cell_type":"markdown","source":"### A. Modelo Binario Jaccard #","metadata":{}},{"cell_type":"code","source":"def search_jaccard(query, df, inverted_index):\n    query_tokens = set(preprocess_text(query))\n    \n    if not query_tokens:\n        return []\n    \n    # Recuperar documentos candidatos que contienen al menos un término\n    candidate_ids = set()\n    for token in query_tokens:\n        if token in inverted_index:\n            for doc_id, _ in inverted_index[token]:\n                candidate_ids.add(doc_id)\n    \n    results = []\n    for doc_id in candidate_ids:\n        doc_tokens = set(df.at[doc_id, 'tokens'])\n        \n        intersection = len(query_tokens.intersection(doc_tokens))\n        union = len(query_tokens.union(doc_tokens))\n        \n        jaccard_score = intersection / union if union > 0 else 0\n        \n        if jaccard_score > 0:\n            results.append((doc_id, jaccard_score))\n            \n    return sorted(results, key=lambda x: x[1], reverse=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:15:35.396969Z","iopub.execute_input":"2025-11-23T16:15:35.397294Z","iopub.status.idle":"2025-11-23T16:15:35.403971Z","shell.execute_reply.started":"2025-11-23T16:15:35.397271Z","shell.execute_reply":"2025-11-23T16:15:35.402867Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### TF-IDF","metadata":{}},{"cell_type":"code","source":"# Inicializar y ajustar el vectorizador una sola vez\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_text'])\n\ndef search_tfidf(query, vectorizer, matrix):\n    # Preprocesar y vectorizar la consulta\n    query_processed = ' '.join(preprocess_text(query))\n    query_vec = vectorizer.transform([query_processed])\n    \n    # Calcular similitud de coseno\n    cosine_similarities = cosine_similarity(query_vec, matrix).flatten()\n    \n    # Obtener índices con similitud > 0\n    related_docs_indices = cosine_similarities.nonzero()[0]\n    \n    results = []\n    for idx in related_docs_indices:\n        score = cosine_similarities[idx]\n        results.append((idx, score))\n        \n    return sorted(results, key=lambda x: x[1], reverse=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:15:40.02296Z","iopub.execute_input":"2025-11-23T16:15:40.023302Z","iopub.status.idle":"2025-11-23T16:15:42.985874Z","shell.execute_reply.started":"2025-11-23T16:15:40.023277Z","shell.execute_reply":"2025-11-23T16:15:42.984752Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### BM25","metadata":{}},{"cell_type":"code","source":"def compute_avgdl(df_tokens):\n    total_length = sum(len(tokens) for tokens in df_tokens)\n    return total_length / len(df_tokens)\n\n# Pre-cálculo de constantes para BM25\nAVG_DL = compute_avgdl(df['tokens'])\nN_DOCS = len(df)\n\ndef search_bm25(query, inverted_index, df, k1=1.5, b=0.75):\n    query_tokens = preprocess_text(query)\n    scores = defaultdict(float)\n    \n    for token in query_tokens:\n        if token not in inverted_index:\n            continue\n            \n        # Datos del término en el corpus\n        posting_list = inverted_index[token]\n        doc_count_containing_term = len(posting_list)\n        \n        # Cálculo del IDF (Inverse Document Frequency)\n        idf = math.log((N_DOCS - doc_count_containing_term + 0.5) / (doc_count_containing_term + 0.5) + 1)\n        \n        for doc_id, freq in posting_list:\n            doc_len = len(df.at[doc_id, 'tokens'])\n            \n            # Fórmula BM25\n            numerator = freq * (k1 + 1)\n            denominator = freq + k1 * (1 - b + b * (doc_len / AVG_DL))\n            \n            scores[doc_id] += idf * (numerator / denominator)\n            \n    return sorted(scores.items(), key=lambda x: x[1], reverse=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:15:53.490052Z","iopub.execute_input":"2025-11-23T16:15:53.490444Z","iopub.status.idle":"2025-11-23T16:15:53.5279Z","shell.execute_reply.started":"2025-11-23T16:15:53.490391Z","shell.execute_reply":"2025-11-23T16:15:53.526751Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Interfaz de Búsqueda y Ranking","metadata":{}},{"cell_type":"code","source":"def execute_query(query, model_type='tfidf', top_n=10):\n    print(f\"\\nConsulta: '{query}' | Modelo: {model_type.upper()}\")\n    print(\"-\" * 60)\n    \n    if model_type == 'jaccard':\n        results = search_jaccard(query, df, inverted_index)\n    elif model_type == 'tfidf':\n        results = search_tfidf(query, tfidf_vectorizer, tfidf_matrix)\n    elif model_type == 'bm25':\n        results = search_bm25(query, inverted_index, df)\n    else:\n        print(\"Modelo no reconocido.\")\n        return\n\n    # Mostrar top N resultados\n    for rank, (doc_id, score) in enumerate(results[:top_n], 1):\n        title = df.at[doc_id, 'title']\n        # Recortar descripción para visualización\n        desc = df.at[doc_id, 'description'][:100] + \"...\" \n        print(f\"Rank {rank} | Score: {score:.4f} | ID: {doc_id}\")\n        print(f\"Vino: {title}\")\n        print(f\"Desc: {desc}\\n\")\n\n# Ejemplo de uso\nexecute_query(\"aromas of tropical fruit and citrus\", model_type='bm25')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:15:57.142234Z","iopub.execute_input":"2025-11-23T16:15:57.142607Z","iopub.status.idle":"2025-11-23T16:15:57.69279Z","shell.execute_reply.started":"2025-11-23T16:15:57.142581Z","shell.execute_reply":"2025-11-23T16:15:57.69167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Evaluación","metadata":{}},{"cell_type":"code","source":"def calculate_metrics(retrieved_ids, relevant_ids):\n    \"\"\"\n    Calcula Precision@K y Recall@K.\n    retrieved_ids: Lista de IDs recuperados por el sistema (ordenados por ranking).\n    relevant_ids: Set de IDs que son verdaderamente relevantes (Ground Truth).\n    \"\"\"\n    if not retrieved_ids:\n        return 0.0, 0.0\n        \n    relevant_retrieved = [doc for doc in retrieved_ids if doc in relevant_ids]\n    \n    precision = len(relevant_retrieved) / len(retrieved_ids)\n    recall = len(relevant_retrieved) / len(relevant_ids) if relevant_ids else 0.0\n    \n    return precision, recall\n\ndef calculate_ap(retrieved_ids, relevant_ids):\n    \"\"\"Calcula Average Precision (AP) para una consulta.\"\"\"\n    if not relevant_ids:\n        return 0.0\n        \n    precision_sum = 0.0\n    relevant_count = 0\n    \n    for i, doc_id in enumerate(retrieved_ids):\n        if doc_id in relevant_ids:\n            relevant_count += 1\n            precision_at_i = relevant_count / (i + 1)\n            precision_sum += precision_at_i\n            \n    return precision_sum / len(relevant_ids)\n\ndef evaluate_system(test_queries, model_function):\n    \"\"\"\n    test_queries: Diccionario {'query_text': {relevant_id_1, relevant_id_2, ...}}\n    \"\"\"\n    map_sum = 0\n    \n    print(f\"{'Query':<30} | {'Precision':<10} | {'Recall':<10} | {'AP':<10}\")\n    print(\"-\" * 70)\n    \n    for query, relevant_ids in test_queries.items():\n        # Ejecutar búsqueda (obtenemos todos los resultados para calcular métricas completas)\n        results = model_function(query) \n        retrieved_ids = [doc_id for doc_id, _ in results]\n        \n        # Calcular métricas (ejemplo @10 para P/R, todo para AP)\n        p, r = calculate_metrics(retrieved_ids[:10], relevant_ids)\n        ap = calculate_ap(retrieved_ids, relevant_ids)\n        \n        map_sum += ap\n        print(f\"{query[:28]:<30} | {p:.4f}     | {r:.4f}     | {ap:.4f}\")\n        \n    print(\"-\" * 70)\n    print(f\"Mean Average Precision (MAP): {map_sum / len(test_queries):.4f}\")\n\n# NOTA: Para usar esto, debes crear un pequeño set de validación manual ('qrels')\n# Ejemplo ficticio de cómo se vería la estructura para probar:\n# qrels = {\n#    \"tropical fruit\": {0, 15, 230}, # IDs que tú sabes que son relevantes\n#    \"dry red wine\": {1, 50, 99}\n# }\n# evaluate_system(qrels, lambda q: search_bm25(q, inverted_index, df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:16:26.984647Z","iopub.execute_input":"2025-11-23T16:16:26.984999Z","iopub.status.idle":"2025-11-23T16:16:26.99461Z","shell.execute_reply.started":"2025-11-23T16:16:26.984971Z","shell.execute_reply":"2025-11-23T16:16:26.993495Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6. Evaluación Comparativa y Generación de Métricas para el Informe\n\ndef generate_ground_truth(df, query_term, min_relevance=10):\n    \"\"\"\n    Genera un 'Ground Truth' artificial para propósitos académicos.\n    Asume que cualquier vino que contenga el término exacto en su descripción \n    es relevante.\n    \"\"\"\n    # Buscamos índices donde el término aparece en los tokens procesados\n    relevant_indices = set()\n    query_stemmed = preprocess_text(query_term)[0] # Usamos el stem para ser consistentes\n    \n    for idx, tokens in enumerate(df['tokens']):\n        if query_stemmed in tokens:\n            relevant_indices.add(idx)\n            \n    # Limitamos para no tener miles de relevantes, solo para probar ranking\n    return relevant_indices\n\n# 1. Definimos consultas de prueba y generamos su Ground Truth\ntest_queries = {\n    \"tropical fruit\": generate_ground_truth(df, \"tropical\"),\n    \"dry red\": generate_ground_truth(df, \"dry\"),\n    \"sweet finish\": generate_ground_truth(df, \"sweet\")\n}\n\nprint(f\"Ground Truth generado para {len(test_queries)} consultas de prueba.\\n\")\n\n# 2. Configuración de experimentos\nmodels = ['jaccard', 'tfidf', 'bm25']\nmetrics_results = []\n\nfor model_name in models:\n    print(f\"Evaluando modelo: {model_name}...\")\n    \n    avg_precision = 0\n    avg_recall = 0\n    map_score = 0\n    \n    for query_text, relevant_ids in test_queries.items():\n        # Ejecutar búsqueda según el modelo\n        if model_name == 'jaccard':\n            results = search_jaccard(query_text, df, inverted_index)\n        elif model_name == 'tfidf':\n            results = search_tfidf(query_text, tfidf_vectorizer, tfidf_matrix)\n        elif model_name == 'bm25':\n            results = search_bm25(query_text, inverted_index, df)\n            \n        # Obtenemos solo los IDs recuperados (Top 20 para el cálculo)\n        retrieved_ids = [doc_id for doc_id, _ in results]\n        \n        # Calcular métricas individuales\n        p, r = calculate_metrics(retrieved_ids[:20], relevant_ids) # Precision@20\n        ap = calculate_ap(retrieved_ids, relevant_ids)\n        \n        avg_precision += p\n        avg_recall += r\n        map_score += ap\n    \n    # Promediar métricas entre todas las consultas para este modelo\n    n_queries = len(test_queries)\n    metrics_results.append({\n        'Modelo': model_name.upper(),\n        'Mean Precision@20': round(avg_precision / n_queries, 4),\n        'Mean Recall@20': round(avg_recall / n_queries, 4),\n        'MAP (Mean Avg Precision)': round(map_score / n_queries, 4)\n    })\n\n# 3. Mostrar Tabla de Resultados (DataFrame para visualizar en el informe)\ndf_results = pd.DataFrame(metrics_results)\nprint(\"\\n=== Tabla Comparativa de Rendimiento ===\")\ndf_results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:26:41.071241Z","iopub.execute_input":"2025-11-23T16:26:41.072033Z","iopub.status.idle":"2025-11-23T16:26:44.105347Z","shell.execute_reply.started":"2025-11-23T16:26:41.071999Z","shell.execute_reply":"2025-11-23T16:26:44.104446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 7. Interfaz de Usuario (CLI)\nimport sys\n\ndef run_cli():\n    \"\"\"\n    Inicia la interfaz de línea de comandos para el sistema de recuperación.\n    Cumple con el requerimiento C del proyecto.\n    \"\"\"\n    print(\"=\"*60)\n    print(\"      SISTEMA DE RECUPERACIÓN DE INFORMACIÓN DE VINOS\")\n    print(\"      (Jaccard | TF-IDF | BM25)\")\n    print(\"=\"*60)\n    \n    while True:\n        print(\"\\nOpciones:\")\n        print(\"1. Buscar\")\n        print(\"2. Salir\")\n        \n        choice = input(\"\\nSeleccione una opción: \").strip()\n        \n        if choice == '2':\n            print(\"Saliendo del sistema...\")\n            break\n            \n        if choice == '1':\n            query = input(\"Ingrese su consulta (ej. 'sweet tropical'): \").strip()\n            if not query:\n                continue\n                \n            print(\"\\nModelos disponibles: [1] Jaccard, [2] TF-IDF, [3] BM25\")\n            model_choice = input(\"Seleccione algoritmo (default BM25): \").strip()\n            \n            # Mapeo de selección a nombre de modelo\n            if model_choice == '1':\n                model = 'jaccard'\n            elif model_choice == '2':\n                model = 'tfidf'\n            else:\n                model = 'bm25'\n            \n            # Ejecutar búsqueda usando la función que definimos antes\n            try:\n                execute_query(query, model_type=model, top_n=5)\n            except Exception as e:\n                print(f\"Error durante la búsqueda: {e}\")\n        else:\n            print(\"Opción no válida.\")\n\n# Descomentar la siguiente línea para probar la interfaz interactiva en el notebook\nrun_cli()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T16:32:48.801084Z","iopub.execute_input":"2025-11-23T16:32:48.8016Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LIBRERIA","metadata":{}},{"cell_type":"code","source":"def preprocess_text(text):\n    # Convertir a minúsculas\n    text = text.lower()\n    \n    # Eliminar puntuación\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # Tokenización\n    tokens = word_tokenize(text)\n    \n    # Stopwords y Stemming\n    clean_tokens = [\n        STEMMER.stem(token) \n        for token in tokens \n        if token not in STOPWORDS and token.isalpha()\n    ]\n    \n    return clean_tokens\n\ndef build_inverted_index(df_tokens):\n    inverted_index = defaultdict(list)\n    \n    for doc_id, tokens in enumerate(df_tokens):\n        # Contar frecuencia de términos en el documento actual\n        term_freq = defaultdict(int)\n        for token in tokens:\n            term_freq[token] += 1\n            \n        # Actualizar índice invertido\n        for token, freq in term_freq.items():\n            inverted_index[token].append((doc_id, freq))\n            \n    return inverted_index\n\n\ndef search_jaccard(query, df, inverted_index):\n    query_tokens = set(preprocess_text(query))\n    \n    if not query_tokens:\n        return []\n    \n    # Recuperar documentos candidatos que contienen al menos un término\n    candidate_ids = set()\n    for token in query_tokens:\n        if token in inverted_index:\n            for doc_id, _ in inverted_index[token]:\n                candidate_ids.add(doc_id)\n    \n    results = []\n    for doc_id in candidate_ids:\n        doc_tokens = set(df.at[doc_id, 'tokens'])\n        \n        intersection = len(query_tokens.intersection(doc_tokens))\n        union = len(query_tokens.union(doc_tokens))\n        \n        jaccard_score = intersection / union if union > 0 else 0\n        \n        if jaccard_score > 0:\n            results.append((doc_id, jaccard_score))\n            \n    return sorted(results, key=lambda x: x[1], reverse=True)\n\n\n# Inicializar y ajustar el vectorizador una sola vez\ntfidf_vectorizer = TfidfVectorizer()\ntfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_text'])\n\ndef search_tfidf(query, vectorizer, matrix):\n    # Preprocesar y vectorizar la consulta\n    query_processed = ' '.join(preprocess_text(query))\n    query_vec = vectorizer.transform([query_processed])\n    \n    # Calcular similitud de coseno\n    cosine_similarities = cosine_similarity(query_vec, matrix).flatten()\n    \n    # Obtener índices con similitud > 0\n    related_docs_indices = cosine_similarities.nonzero()[0]\n    \n    results = []\n    for idx in related_docs_indices:\n        score = cosine_similarities[idx]\n        results.append((idx, score))\n        \n    return sorted(results, key=lambda x: x[1], reverse=True)\n\n\ndef compute_avgdl(df_tokens):\n    total_length = sum(len(tokens) for tokens in df_tokens)\n    return total_length / len(df_tokens)\n\n# Pre-cálculo de constantes para BM25\nAVG_DL = compute_avgdl(df['tokens'])\nN_DOCS = len(df)\n\ndef search_bm25(query, inverted_index, df, k1=1.5, b=0.75):\n    query_tokens = preprocess_text(query)\n    scores = defaultdict(float)\n    \n    for token in query_tokens:\n        if token not in inverted_index:\n            continue\n            \n        # Datos del término en el corpus\n        posting_list = inverted_index[token]\n        doc_count_containing_term = len(posting_list)\n        \n        # Cálculo del IDF (Inverse Document Frequency)\n        idf = math.log((N_DOCS - doc_count_containing_term + 0.5) / (doc_count_containing_term + 0.5) + 1)\n        \n        for doc_id, freq in posting_list:\n            doc_len = len(df.at[doc_id, 'tokens'])\n            \n            # Fórmula BM25\n            numerator = freq * (k1 + 1)\n            denominator = freq + k1 * (1 - b + b * (doc_len / AVG_DL))\n            \n            scores[doc_id] += idf * (numerator / denominator)\n            \n    return sorted(scores.items(), key=lambda x: x[1], reverse=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import string\nimport numpy as np\nimport math\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\nfrom collections import defaultdict\n\nnltk.download('punkt')\nnltk.download('stopwords')\nSTOPWORDS = set(stopwords.words('spanish')) # O 'english' según tu data\nSTEMMER = SnowballStemmer('spanish')        # O 'english'\n\n-----------------------------------------------------------------------------------------------------\n\ndef preprocesar_texto(texto):\n    # Verificación de seguridad (por si el texto viene vacío)\n    if not isinstance(texto, str): return []\n    \n    # Convertir a minúsculas\n    texto = texto.lower()\n    \n    # Eliminar puntuación \n    texto = texto.translate(str.maketrans('', '', string.punctuation))\n    \n    # Tokenización \n    tokens = word_tokenize(texto)\n    \n    # Stopwords y Stemming \n    tokens_limpios = [\n        STEMMER.stem(token)               \n        for token in tokens \n        if token not in STOPWORDS and token.isalpha() \n    ]\n    \n    return tokens_limpios\n\n------------------------------------------------------------------------------------------------------\n\ndef construir_indice_invertido(lista_de_tokens_por_doc):\n    #  lista vacía\n    indice_invertido = defaultdict(list)\n    \n    for id_doc, tokens in enumerate(lista_de_tokens_por_doc):\n        # frecuencia\n        frecuencia_local = defaultdict(int)\n        for token in tokens:\n            frecuencia_local[token] += 1\n        for token, frecuencia in frecuencia_local.items():\n            indice_invertido[token].append((id_doc, frecuencia))\n            \n    return indice_invertido\n\n--------------------------------------------------------------------------------------------------------\n\ndef calcular_coseno(vec_a, vec_b):\n    vec_a = np.array(vec_a)\n    vec_b = np.array(vec_b)\n\n    # Producto Punto \n    producto_punto = np.dot(vec_a, vec_b)\n    \n    # Normal \n    # Es la raíz cuadrada de la suma de los elementos al cuadrado\n    norma_a = np.linalg.norm(vec_a)\n    norma_b = np.linalg.norm(vec_b)\n    \n    if norma_a == 0 or norma_b == 0:\n        return 0.0\n    return producto_punto / (norma_a * norma_b)\n\n--------------------------------------------------------------------------------------------------------\n\ndef generar_matriz_booleana(lista_docs_tokens):\n    vocabulario = sorted(list(set(token for doc in lista_docs_tokens for token in doc)))\n    matriz = []\n    # Construir la fila para cada documento\n    for doc_tokens in lista_docs_tokens:\n        fila = []\n        for palabra in vocabulario:\n            if palabra in doc_tokens:\n                fila.append(1) \n            else:\n                fila.append(0) \n        matriz.append(fila)\n    return np.array(matriz), vocabulario\n\n--------------------------------------------------------------------------------------------------------\n\ndef generar_tfidf(lista_docs_tokens):\n    # Obtener Vocabulario \n    vocabulario = sorted(list(set(token for doc in lista_docs_tokens for token in doc)))\n    N = len(lista_docs_tokens)\n    \n    # Calcular IDF \n    idf_diccionario = {}\n    for palabra in vocabulario:\n        conteo_docs_con_palabra = sum(1 for doc in lista_docs_tokens if palabra in doc)\n        idf_diccionario[palabra] = math.log10(N / conteo_docs_con_palabra)\n    \n    matriz_tfidf = []\n    # Calcular TF y multiplicar por IDF \n    for doc_tokens in lista_docs_tokens:\n        fila = []\n        total_palabras_doc = len(doc_tokens)\n        \n        for palabra in vocabulario:\n            # TF\n            conteo_en_doc = doc_tokens.count(palabra)\n            if total_palabras_doc > 0:\n                tf = conteo_en_doc / total_palabras_doc\n            else:\n                tf = 0\n            \n            # TF-IDF\n            valor_tfidf = tf * idf_diccionario[palabra]\n            fila.append(valor_tfidf)\n            \n        matriz_tfidf.append(fila)\n        \n    return np.array(matriz_tfidf), vocabulario","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}