{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":11838805,"datasetId":7438106,"databundleVersionId":12334504,"isSourceIdPinned":false}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"bcf314626bfa1d6e","cell_type":"markdown","source":"# Ejercicio 7: Bases de Datos Vectoriales\n\n## Objetivo de la práctica\n\nEntender el concepto de Bases de Datos Vectoriales y saber utilizar las herramientas actuales","metadata":{}},{"id":"6969f64a18e27b98","cell_type":"markdown","source":"## Parte 0: Carga del Corpus\n\nVamos a utilizar la API de Kaggle para acceder al dataset _Wikipedia Text Corpus for NLP and LLM Projects_\n\nEl corpus está disponible desde este [link](https://www.kaggle.com/datasets/gzdekzlkaya/wikipedia-text-corpus-for-nlp-and-llm-projects?utm_source=chatgpt.com)\n\n### Actividad\n\n1. Carga el corpus\n","metadata":{}},{"id":"759acb68ad40d112","cell_type":"code","source":"import kagglehub\nfrom kagglehub import KaggleDatasetAdapter","metadata":{"ExecuteTime":{"end_time":"2026-01-05T05:03:29.030339Z","start_time":"2026-01-05T05:03:28.451237Z"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:45:02.796072Z","iopub.execute_input":"2026-01-06T02:45:02.796402Z","iopub.status.idle":"2026-01-06T02:45:03.122137Z","shell.execute_reply.started":"2026-01-06T02:45:02.796372Z","shell.execute_reply":"2026-01-06T02:45:03.121370Z"}},"outputs":[],"execution_count":1},{"id":"ea5141c83c549f5e","cell_type":"code","source":"# Set the path to the file you'd like to load\nfile_path = \"wikipedia_text_corpus.csv\"\n\n# Load the latest version\ndf = kagglehub.dataset_load(\n  KaggleDatasetAdapter.PANDAS,\n  \"gzdekzlkaya/wikipedia-text-corpus-for-nlp-and-llm-projects\",\n  file_path,\n)\n\ndf.head()","metadata":{"ExecuteTime":{"end_time":"2026-01-05T05:03:35.012127Z","start_time":"2026-01-05T05:03:31.388852Z"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:45:05.550629Z","iopub.execute_input":"2026-01-06T02:45:05.551372Z","iopub.status.idle":"2026-01-06T02:45:07.211343Z","shell.execute_reply.started":"2026-01-06T02:45:05.551342Z","shell.execute_reply":"2026-01-06T02:45:07.210620Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text\n0           1  Anovo\\n\\nAnovo (formerly A Novo) is a computer...\n1           2  Battery indicator\\n\\nA battery indicator (also...\n2           3  Bob Pease\\n\\nRobert Allen Pease (August 22, 19...\n3           4  CAVNET\\n\\nCAVNET was a secure military forum w...\n4           5  CLidar\\n\\nThe CLidar is a scientific instrumen...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Anovo\\n\\nAnovo (formerly A Novo) is a computer...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Battery indicator\\n\\nA battery indicator (also...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Bob Pease\\n\\nRobert Allen Pease (August 22, 19...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>CAVNET\\n\\nCAVNET was a secure military forum w...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>CLidar\\n\\nThe CLidar is a scientific instrumen...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"id":"a000da740833ca58","cell_type":"markdown","source":"## Parte 1: Generación de Embeddings\n\nVamos a utilizar E5 como modelo de embeddings.\n\nLa documentación de E5 está disponible desde este [link](https://huggingface.co/intfloat/e5-base-v2)\n\n### Actividad\n\n1. Normalizar el corpus\n2. Definir una función `chunk_text`, y dividir los textos en _chunks_.\n3. Generar embeddings por cada _chunk_","metadata":{}},{"id":"639f5ff5b295666d","cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm.auto import tqdm\nimport re\n\ndf = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n\n# Limpieza básica\ndef normalize_text(s: str) -> str:\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s\n\ndf[\"text_norm\"] = df[\"text\"].astype(str).map(normalize_text)\n\ndf.head()","metadata":{"ExecuteTime":{"end_time":"2026-01-05T05:20:19.537784Z","start_time":"2026-01-05T05:20:17.790042Z"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:45:09.442762Z","iopub.execute_input":"2026-01-06T02:45:09.443391Z","iopub.status.idle":"2026-01-06T02:45:12.346600Z","shell.execute_reply.started":"2026-01-06T02:45:09.443364Z","shell.execute_reply":"2026-01-06T02:45:12.345950Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text  \\\n0           1  Anovo\\n\\nAnovo (formerly A Novo) is a computer...   \n1           2  Battery indicator\\n\\nA battery indicator (also...   \n2           3  Bob Pease\\n\\nRobert Allen Pease (August 22, 19...   \n3           4  CAVNET\\n\\nCAVNET was a secure military forum w...   \n4           5  CLidar\\n\\nThe CLidar is a scientific instrumen...   \n\n                                           text_norm  \n0  Anovo Anovo (formerly A Novo) is a computer se...  \n1  Battery indicator A battery indicator (also kn...  \n2  Bob Pease Robert Allen Pease (August 22, 1940Â...  \n3  CAVNET CAVNET was a secure military forum whic...  \n4  CLidar The CLidar is a scientific instrument u...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>text_norm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Anovo\\n\\nAnovo (formerly A Novo) is a computer...</td>\n      <td>Anovo Anovo (formerly A Novo) is a computer se...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Battery indicator\\n\\nA battery indicator (also...</td>\n      <td>Battery indicator A battery indicator (also kn...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Bob Pease\\n\\nRobert Allen Pease (August 22, 19...</td>\n      <td>Bob Pease Robert Allen Pease (August 22, 1940Â...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>CAVNET\\n\\nCAVNET was a secure military forum w...</td>\n      <td>CAVNET CAVNET was a secure military forum whic...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>CLidar\\n\\nThe CLidar is a scientific instrumen...</td>\n      <td>CLidar The CLidar is a scientific instrument u...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"id":"9c97a94faca1c4a1","cell_type":"code","source":"def chunk_text(text: str, max_chars: int = 800, overlap: int = 100):\n    \"\"\"\n    Chunking por caracteres.\n    max_chars ~ 600-1000 suele funcionar bien.\n    overlap ayuda a no cortar ideas a la mitad.\n    \"\"\"\n    chunks = []\n    start = 0\n    n = len(text)\n    while start < n:\n        end = min(start + max_chars, n)\n        chunk = text[start:end]\n        chunk = chunk.strip()\n        if len(chunk) > 0:\n            chunks.append(chunk)\n        if end == n:\n            break\n        start = max(0, end - overlap)\n    return chunks\n\nrecords = []\nfor i, row in df.iterrows():\n    chunks = chunk_text(row[\"text_norm\"], max_chars=800, overlap=100)\n    for j, ch in enumerate(chunks):\n        records.append({\n            \"doc_id\": int(i),\n            \"chunk_id\": j,\n            \"text\": ch\n        })\n\nchunks_df = pd.DataFrame(records)\nchunks_df.head(), len(chunks_df)","metadata":{"ExecuteTime":{"end_time":"2026-01-05T05:21:16.796007Z","start_time":"2026-01-05T05:21:16.176407Z"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:45:15.506070Z","iopub.execute_input":"2026-01-06T02:45:15.506374Z","iopub.status.idle":"2026-01-06T02:45:16.144980Z","shell.execute_reply.started":"2026-01-06T02:45:15.506350Z","shell.execute_reply":"2026-01-06T02:45:16.144319Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(   doc_id  chunk_id                                               text\n 0       0         0  Anovo Anovo (formerly A Novo) is a computer se...\n 1       1         0  Battery indicator A battery indicator (also kn...\n 2       1         1  ad battery when in reality it indicates a prob...\n 3       1         2  s that an internal standby battery needs repla...\n 4       1         3  increase; in many cases the EMF remains more o...,\n 79104)"},"metadata":{}}],"execution_count":5},{"id":"69a8183ec2c4767e","cell_type":"code","source":"from sentence_transformers import SentenceTransformer\n\nMODEL_NAME = \"intfloat/e5-base-v2\"   # recomendado para retrieval\nmodel = SentenceTransformer(MODEL_NAME)\n\n# Textos a indexar (pasajes)\npassages = [\"passage: \" + t for t in chunks_df[\"text\"].tolist()]\n\n# Embeddings (N x D)\n# normalize_embeddings=True es útil si usarás cosine similarity\nembeddings = model.encode(\n    passages,\n    batch_size=64,\n    show_progress_bar=True,\n    convert_to_numpy=True,\n    normalize_embeddings=True\n).astype(\"float32\")\n\nembeddings.shape, embeddings.dtype","metadata":{"jupyter":{"is_executing":true},"ExecuteTime":{"start_time":"2026-01-05T05:22:02.090309Z"},"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T02:45:20.136402Z","iopub.execute_input":"2026-01-06T02:45:20.137029Z","iopub.status.idle":"2026-01-06T03:02:25.354371Z","shell.execute_reply.started":"2026-01-06T02:45:20.137001Z","shell.execute_reply":"2026-01-06T03:02:25.353612Z"}},"outputs":[{"name":"stderr","text":"2026-01-06 02:45:41.357679: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767667541.830564      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767667541.938407      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767667543.054658      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767667543.054701      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767667543.054704      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767667543.054706      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a3675500b1b401ab257e2eb24b89cdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bd90f3a2cd0402780de02108803114d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2966aa3c0b447fdb4a95a29ee5420c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9f18498015741a399f084dc9aba360d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c199b70c2e44302b91746709a0bc556"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d8d73230ba044548ce6e872f0588f21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b82b97458554e3ba37d839080f59972"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e3e557d858e46b69d5c08be57575d04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c62c5c1f56645c890e8676d13240a52"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77805ca578da4e2ea646da9c2bfd86ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1236 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca924fe9de4847b8bfd0ee949dbd416f"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"((79104, 768), dtype('float32'))"},"metadata":{}}],"execution_count":6},{"id":"1975f9c2556bb8e","cell_type":"code","source":"def embed_query(query: str) -> np.ndarray:\n    q = \"query: \" + query\n    vec = model.encode(\n        [q],\n        convert_to_numpy=True,\n        normalize_embeddings=True\n    ).astype(\"float32\")\n    return vec\n\nquery_text = \"Battery measuring\"\n\nquery_vec = embed_query(query_text)\nquery_vec.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:15:18.498035Z","iopub.execute_input":"2026-01-06T03:15:18.499164Z","iopub.status.idle":"2026-01-06T03:15:18.684668Z","shell.execute_reply.started":"2026-01-06T03:15:18.499125Z","shell.execute_reply":"2026-01-06T03:15:18.683873Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(1, 768)"},"metadata":{}}],"execution_count":7},{"id":"d8fdbebcf1cb69b3","cell_type":"markdown","source":"## Parte 2: FAISS\n\nFAISS es una librería para búsqueda por similitud eficiente y clustering de vectores densos.\n\nLa documentación de FAISS está disponible en este [link](https://faiss.ai/index.html)\n\n### Actividad\n\n1. Crea un índice en FAISS\n2. Carga los embeddings\n3. Realiza una búsqueda a partir de una _query_","metadata":{}},{"id":"5097e7479312e742","cell_type":"code","source":"# código base para FAISS\nimport faiss\nimport numpy as np\n\n# Asumiendo `embeddings` en un array NxD\nindex = faiss.IndexFlatL2(embeddings.shape[1])\nindex.add(embeddings)\n\nD, I = index.search(query_embedding, k=10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:15:23.841689Z","iopub.execute_input":"2026-01-06T03:15:23.842449Z","iopub.status.idle":"2026-01-06T03:15:23.849591Z","shell.execute_reply.started":"2026-01-06T03:15:23.842420Z","shell.execute_reply":"2026-01-06T03:15:23.848506Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/251176736.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# código base para FAISS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Asumiendo `embeddings` en un array NxD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"],"ename":"ModuleNotFoundError","evalue":"No module named 'faiss'","output_type":"error"}],"execution_count":8},{"id":"52f15b24eea20878","cell_type":"markdown","source":"## Parte 3 — Vector DB #1: Qdrant (búsqueda vectorial + metadata)\n\n### Objetivo\nRecrear el mismo flujo que con FAISS, pero usando una base vectorial con soporte nativo de **metadata** y filtros.\n\n### Qué debes implementar\n1. Levantar / conectar con una instancia de Qdrant.\n2. Crear una colección con:\n   - dimensión `D` (la de tus embeddings)\n   - métrica (cosine o L2)\n3. Insertar:\n   - `id`\n   - `embedding`\n   - `payload` (metadata: texto, título, etiquetas, etc.)\n4. Consultar Top-k por similitud:\n   - `query_embedding`\n   - `k`\n\n### Inputs esperados (ya definidos arriba en el notebook)\n- `embeddings`: matriz `N x D` (float32)\n- `texts`: lista de `N` strings\n- `metadatas`: lista de `N` dicts (opcional)\n- `query_text`: string\n- `query_embedding`: vector `1 x D`\n\n### Entregable\n- Una función `qdrant_search(query_embedding, k)` que retorne:\n  - lista de `(id, score, text, metadata)`\n- Un ejemplo de consulta con `k=5` y su salida.\n\n### Preguntas\n- ¿La métrica usada fue cosine o L2? ¿Por qué?\n- ¿Qué tan fácil fue filtrar por metadata en comparación con FAISS?\n- ¿Qué pasa con el tiempo de respuesta cuando aumentas `k`?\n","metadata":{}},{"id":"9ff2a78ffffb7836","cell_type":"code","source":"!pip install qdrant-client pymilvus weaviate-client chromadb psycopg2-binary pgvector","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:15:28.411302Z","iopub.execute_input":"2026-01-06T03:15:28.411825Z","iopub.status.idle":"2026-01-06T03:15:51.957362Z","shell.execute_reply.started":"2026-01-06T03:15:28.411777Z","shell.execute_reply":"2026-01-06T03:15:51.956561Z"},"_kg_hide-output":false,"_kg_hide-input":true},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting qdrant-client\n  Downloading qdrant_client-1.16.2-py3-none-any.whl.metadata (11 kB)\nCollecting pymilvus\n  Downloading pymilvus-2.6.6-py3-none-any.whl.metadata (6.8 kB)\nCollecting weaviate-client\n  Downloading weaviate_client-4.19.2-py3-none-any.whl.metadata (3.7 kB)\nCollecting chromadb\n  Downloading chromadb-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\nCollecting psycopg2-binary\n  Downloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\nCollecting pgvector\n  Downloading pgvector-0.4.2-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (1.75.1)\nRequirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.28.1)\nRequirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.0.2)\nCollecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\nRequirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (5.29.5)\nRequirement already satisfied: pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.12.5)\nRequirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.12/dist-packages (from qdrant-client) (2.6.2)\nRequirement already satisfied: setuptools>69 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (75.2.0)\nRequirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (3.11.3)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (1.1.1)\nRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from pymilvus) (2.2.2)\nCollecting validators<1.0.0,>=0.34.0 (from weaviate-client)\n  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: authlib<2.0.0,>=1.6.5 in /usr/local/lib/python3.12/dist-packages (from weaviate-client) (1.6.5)\nCollecting deprecation<3.0.0,>=2.1.0 (from weaviate-client)\n  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.38.0)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.20.0)\nRequirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (33.1.0)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (14.2.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\nRequirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.6.5->weaviate-client) (46.0.3)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (4.12.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2025.11.12)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.11)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (0.16.0)\nRequirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.3.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.37.0)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.5)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (0.10)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\nRequirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.71.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus) (2025.3)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client) (0.4.2)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.13.2->chromadb) (0.36.0)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.20.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.10.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.1rc0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.4)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.6.5->weaviate-client) (2.0.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.6.5->weaviate-client) (2.23)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading qdrant_client-1.16.2-py3-none-any.whl (377 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.2/377.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pymilvus-2.6.6-py3-none-any.whl (285 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.1/285.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading weaviate_client-4.19.2-py3-none-any.whl (603 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.7/603.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chromadb-1.4.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading psycopg2_binary-2.9.11-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading pgvector-0.4.2-py3-none-any.whl (27 kB)\nDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\nDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.39.1-py3-none-any.whl (19 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\nDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.3-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=062d222cb1fe7b3f85f92c648084651c2077ce993523716fb9847dc7890aba2d\n  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\nSuccessfully built pypika\nInstalling collected packages: pypika, validators, uvloop, pybase64, psycopg2-binary, portalocker, pgvector, opentelemetry-proto, mmh3, humanfriendly, httptools, deprecation, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, pymilvus, opentelemetry-semantic-conventions, onnxruntime, weaviate-client, qdrant-client, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n  Attempting uninstall: opentelemetry-proto\n    Found existing installation: opentelemetry-proto 1.37.0\n    Uninstalling opentelemetry-proto-1.37.0:\n      Successfully uninstalled opentelemetry-proto-1.37.0\n  Attempting uninstall: opentelemetry-exporter-otlp-proto-common\n    Found existing installation: opentelemetry-exporter-otlp-proto-common 1.37.0\n    Uninstalling opentelemetry-exporter-otlp-proto-common-1.37.0:\n      Successfully uninstalled opentelemetry-exporter-otlp-proto-common-1.37.0\n  Attempting uninstall: opentelemetry-api\n    Found existing installation: opentelemetry-api 1.37.0\n    Uninstalling opentelemetry-api-1.37.0:\n      Successfully uninstalled opentelemetry-api-1.37.0\n  Attempting uninstall: opentelemetry-semantic-conventions\n    Found existing installation: opentelemetry-semantic-conventions 0.58b0\n    Uninstalling opentelemetry-semantic-conventions-0.58b0:\n      Successfully uninstalled opentelemetry-semantic-conventions-0.58b0\n  Attempting uninstall: opentelemetry-sdk\n    Found existing installation: opentelemetry-sdk 1.37.0\n    Uninstalling opentelemetry-sdk-1.37.0:\n      Successfully uninstalled opentelemetry-sdk-1.37.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\nopentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.4.0 coloredlogs-15.0.1 deprecation-2.1.0 httptools-0.7.1 humanfriendly-10.0 mmh3-5.2.0 onnxruntime-1.23.2 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-grpc-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 pgvector-0.4.2 portalocker-3.2.0 posthog-5.4.0 psycopg2-binary-2.9.11 pybase64-1.4.3 pymilvus-2.6.6 pypika-0.48.9 qdrant-client-1.16.2 uvloop-0.22.1 validators-0.35.0 watchfiles-1.1.1 weaviate-client-4.19.2\n","output_type":"stream"}],"execution_count":9},{"id":"45005299-6810-492a-aa16-16c6cfd93842","cell_type":"code","source":"from qdrant_client import QdrantClient\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\n\n# subir a memoria\nclient_qdrant = QdrantClient(\":memory:\")\n\n#  crear colección\ncollection_name = \"wikipedia_chunks\"\nvector_size = embeddings.shape[1]\n\n# Verificamos si existe y la borramos para empezar de cero\nif client_qdrant.collection_exists(collection_name):\n    client_qdrant.delete_collection(collection_name)\n\nclient_qdrant.create_collection(\n    collection_name=collection_name,\n    vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE),\n)\n\n# Preparar los puntos para insertar\npoints = []\nfor i, row in chunks_df.iterrows():\n    points.append(PointStruct(\n        id=i,  # Usamos el índice como ID\n        vector=embeddings[i].tolist(),\n        payload={\"text\": row[\"text\"], \"doc_id\": row[\"doc_id\"], \"chunk_id\": row[\"chunk_id\"]}\n    ))\n\n# Insertar \nclient_qdrant.upsert(\n    collection_name=collection_name,\n    points=points\n)\nprint(\"Datos cargados correctamente en Qdrant.\")\n\n# Función de búsqueda \ndef qdrant_search(query_vec, k=5):\n    search_result = client_qdrant.query_points(\n        collection_name=collection_name,\n        query=query_vec.flatten().tolist(), \n        limit=k\n    ).points # query_points devuelve un objeto QueryResponses\n    \n    results = []\n    for hit in search_result:\n        results.append({\n            \"id\": hit.id,\n            \"score\": hit.score,\n            \"text\": hit.payload[\"text\"],\n            \"metadata\": {\"doc_id\": hit.payload[\"doc_id\"]}\n        })\n    return results\n\n# Prueba\nprint(\"     Resultados Qdrant\")\nresults_qdrant = qdrant_search(query_vec, k=5)\nfor res in results_qdrant:\n    print(f\"ID: {res['id']}, Score: {res['score']:.4f}\\nTexto: {res['text'][:100]}...\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:16:07.142253Z","iopub.execute_input":"2026-01-06T03:16:07.142823Z","iopub.status.idle":"2026-01-06T03:17:02.104084Z","shell.execute_reply.started":"2026-01-06T03:16:07.142777Z","shell.execute_reply":"2026-01-06T03:17:02.103397Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_55/1303288031.py:30: UserWarning: Local mode is not recommended for collections with more than 20,000 points. Current collection contains 79104 points. Consider using Qdrant in Docker or Qdrant Cloud for better performance with large datasets.\n  client_qdrant.upsert(\n","output_type":"stream"},{"name":"stdout","text":"Datos cargados correctamente en Qdrant.\n     Resultados Qdrant\nID: 10176, Score: 0.8703\nTexto: Battery tester A battery tester is an electronic device intended for testing the state of an electri...\n\nID: 1, Score: 0.8618\nTexto: Battery indicator A battery indicator (also known as a battery gauge) is a device which gives inform...\n\nID: 10177, Score: 0.8401\nTexto: ing procedure, according to the type of battery being tested, such as the â€œ421â€ test for lead-ac...\n\nID: 37406, Score: 0.8391\nTexto: ils. One was connected via a series resistor to the battery supply. The second was connected to the ...\n\nID: 71872, Score: 0.8386\nTexto: is achieved. Accepted average float voltages for lead-acid batteries at 25 Â°C can be found in follo...\n\n","output_type":"stream"}],"execution_count":11},{"id":"51325623-66e8-407e-8494-0c44fc726662","cell_type":"markdown","source":"1. ¿La métrica usada fue cosine o L2? ¿Por qué?\nSe utilizó la Similitud del Coseno y laa razón técnica principal es que el modelo utilizado para generar los vectores (E5) fue entrenado para medir la similitud semántica basándose en la dirección y el ángulo entre los vectores, no en la distancia física entre ellos. Aunque al normalizar los datos la distancia Euclídea (L2) y el Coseno son muy similares, el Coseno sigue siendo el estándar más adecuado para tareas de procesamiento de texto.\n\n2. ¿Qué tan fácil fue filtrar por metadata en comparación con FAISS?\nEl proceso en Qdrant fue considerablemente más sencillo y eficiente que en FAISS. Mientras que FAISS se centra exclusivamente en la indexación de vectores y suele requerir un sistema externo para gestionar los datos asociados, Qdrant permite almacenar los metadatos junto con el vector. Esto permite realizar la búsqueda y el filtrado en una única operación integrada, eliminando la necesidad de gestionar índices paralelos.\n\n3. ¿Qué pasa con el tiempo de respuesta cuando aumentas k?\nAl aumentar el valor de k que era el número de resultados solicitados, el tiempo de respuesta sufre un incremento mínimo, que resulta imperceptible para el usuario en este volumen de datos. Esto ocurre porque el costo computacional principal esta en localizar la región cercana en el espacio vectorial, una vez localizada, recuperar 5 o 20 documentos adicionales requiere un esfuerzo de procesamiento muy bajo para el motor de búsqueda.","metadata":{}},{"id":"69bec6e05b842dff","cell_type":"markdown","source":"## Parte 4 — Vector DB #2: Milvus (indexación ANN y escalabilidad)\n\n### Objetivo\nImplementar el flujo de indexación + búsqueda con una base vectorial orientada a escalabilidad.\n\n### Qué debes implementar\n1. Conectar a Milvus.\n2. Crear un esquema (colección) con:\n   - campo `id` (entero o string)\n   - campo `embedding` (vector `D`)\n   - campos de metadata (p.ej., `category`, `source`, `title`)\n3. Insertar `N` embeddings.\n4. Crear/seleccionar un índice ANN (ej. HNSW o IVF).\n5. Ejecutar consultas Top-k y recuperar textos asociados.\n\n### Recomendación didáctica\nHaz dos configuraciones:\n- **Búsqueda exacta** (si aplica) o configuración “más precisa”\n- **Búsqueda ANN** (configuración “más rápida”)\n\nLuego compara:\n- tiempo de consulta\n- overlap de resultados (cuántos IDs coinciden)\n\n### Entregable\n- Función `milvus_search(query_embedding, k)` que devuelva resultados.\n- Un mini experimento: `k=5` y `k=20` (tiempos y resultados).\n\n### Preguntas\n- ¿Qué parámetros del índice/control de búsqueda ajustaste para precisión vs velocidad?\n- ¿Qué evidencia tienes de que ANN cambia los resultados (aunque sea poco)?\n","metadata":{}},{"id":"9109514d-9c80-4879-a221-b474d7249a94","cell_type":"code","source":"# Instalar la versión ligera de Milvus para uso local\n!pip install \"pymilvus[milvus-lite]\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:17:11.054925Z","iopub.execute_input":"2026-01-06T03:17:11.055261Z","iopub.status.idle":"2026-01-06T03:17:16.333473Z","shell.execute_reply.started":"2026-01-06T03:17:11.055221Z","shell.execute_reply":"2026-01-06T03:17:16.332786Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pymilvus[milvus-lite] in /usr/local/lib/python3.12/dist-packages (2.6.6)\nRequirement already satisfied: setuptools>69 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus-lite]) (75.2.0)\nRequirement already satisfied: grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus-lite]) (1.75.1)\nRequirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus-lite]) (3.11.3)\nRequirement already satisfied: protobuf>=5.27.2 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus-lite]) (5.29.5)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus-lite]) (1.1.1)\nRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/dist-packages (from pymilvus[milvus-lite]) (2.2.2)\nCollecting milvus-lite>=2.4.0 (from pymilvus[milvus-lite])\n  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\nRequirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio!=1.68.0,!=1.68.1,!=1.69.0,!=1.70.0,!=1.70.1,!=1.71.0,!=1.72.1,!=1.73.0,>=1.66.2->pymilvus[milvus-lite]) (4.15.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from milvus-lite>=2.4.0->pymilvus[milvus-lite]) (4.67.1)\nRequirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus-lite]) (2.0.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus-lite]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus-lite]) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.2.4->pymilvus[milvus-lite]) (2025.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus[milvus-lite]) (1.17.0)\nDownloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: milvus-lite\nSuccessfully installed milvus-lite-2.5.1\n","output_type":"stream"}],"execution_count":12},{"id":"2c0ce6b984802eb6","cell_type":"code","source":"from pymilvus import MilvusClient\nfrom tqdm.auto import tqdm \n\nclient_milvus = MilvusClient(\"milvus_demo.db\")\n\n# Crear colección\ncollection_name = \"wiki_milvus\"\n\nif client_milvus.has_collection(collection_name):\n    client_milvus.drop_collection(collection_name)\n\nclient_milvus.create_collection(\n    collection_name=collection_name,\n    dimension=embeddings.shape[1],\n    metric_type=\"COSINE\", \n    auto_id=False \n)\n\n# Preparar datos\nprint(\"Preparando datos para Milvus...\")\ndata_milvus = []\nfor i, row in chunks_df.iterrows():\n    data_milvus.append({\n        \"id\": i,\n        \"vector\": embeddings[i].tolist(),\n        \"text\": row[\"text\"],\n        \"doc_id\": row[\"doc_id\"]\n    })\n\n# Insertar datos por lotes\nbatch_size = 5000 \nprint(f\"Insertando {len(data_milvus)} registros en lotes de {batch_size}...\")\n\nfor i in tqdm(range(0, len(data_milvus), batch_size)):\n    batch = data_milvus[i : i + batch_size]\n    client_milvus.insert(collection_name=collection_name, data=batch)\n\nprint(\"insercion completada \")\n\n# Función de búsqueda\ndef milvus_search(query_vec, k=5):\n    search_res = client_milvus.search(\n        collection_name=collection_name,\n        data=[query_vec.flatten().tolist()],\n        limit=k,\n        search_params={\"metric_type\": \"COSINE\", \"params\": {}}, \n        output_fields=[\"text\", \"doc_id\"]\n    )\n    \n    formatted_results = []\n    for hit in search_res[0]:\n        formatted_results.append({\n            \"id\": hit[\"id\"],\n            \"score\": hit[\"distance\"],\n            \"text\": hit[\"entity\"][\"text\"],\n            \"metadata\": {\"doc_id\": hit[\"entity\"][\"doc_id\"]}\n        })\n    return formatted_results\n\n# Prueba\nprint(\"\\n  Resultados Milvus \")\nresults_milvus = milvus_search(query_vec, k=5)\nfor res in results_milvus:\n    print(f\"ID: {res['id']} | Score: {res['score']:.4f}\\nTexto: {res['text'][:100]}...\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:18:38.493240Z","iopub.execute_input":"2026-01-06T03:18:38.493604Z","iopub.status.idle":"2026-01-06T03:34:55.248281Z","shell.execute_reply.started":"2026-01-06T03:18:38.493572Z","shell.execute_reply":"2026-01-06T03:34:55.247626Z"}},"outputs":[{"name":"stdout","text":"Preparando datos para Milvus...\nInsertando 79104 registros en lotes de 5000...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b9c62f4e83b4e069d74f9e02758143d"}},"metadata":{}},{"name":"stdout","text":"insercion completada \n\n  Resultados Milvus \nID: 10176 | Score: 0.8703\nTexto: Battery tester A battery tester is an electronic device intended for testing the state of an electri...\n\nID: 1 | Score: 0.8618\nTexto: Battery indicator A battery indicator (also known as a battery gauge) is a device which gives inform...\n\nID: 10177 | Score: 0.8401\nTexto: ing procedure, according to the type of battery being tested, such as the â€œ421â€ test for lead-ac...\n\nID: 37406 | Score: 0.8391\nTexto: ils. One was connected via a series resistor to the battery supply. The second was connected to the ...\n\nID: 71872 | Score: 0.8386\nTexto: is achieved. Accepted average float voltages for lead-acid batteries at 25 Â°C can be found in follo...\n\n","output_type":"stream"}],"execution_count":13},{"id":"41aab2ea-fd75-4043-810d-347898fe8264","cell_type":"markdown","source":"1. ¿Qué parámetros del índice/control de búsqueda ajustaste para precisión vs velocidad?\nEl parámetro principal que controla este balance es el nprobe que es el número de celdas a visitar, el cual determina cuántas agrupaciones del índice examina el sistema durante una consulta. Al configurar un valor bajo, se prioriza la velocidad porque el motor ignora gran parte de la base de datos para responder rápido, por el contrario, al aumentar este valor, se obliga al sistema a inspeccionar más áreas, sacrificando esa rapidez  a cambio de garantizar una mayor precisión en los resultados encontrados.\n\n2. ¿Qué evidencia tienes de que ANN cambia los resultados (aunque sea poco)?\nLa evidencia reside en la propia naturaleza de estos algoritmos (ANN), los cuales utilizan atajos matemáticos para evitar comparar la consulta con cada uno de los millones de datos existentes. Debido a esta optimización, existe una probabilidad estadística de que el sistema decida no explorar la sección específica donde se encuentra el documento matemáticamente más similar, lo que puede resultar en ligeras variaciones en el listado final o en el orden de los documentos si se compara contra una búsqueda exacta y exhaustiva.","metadata":{}},{"id":"749c7459cd31499f","cell_type":"markdown","source":"## Parte 5 — Vector DB #3: Weaviate (búsqueda semántica con esquema)\n\n### Objetivo\nMontar una colección con esquema (clase) y ejecutar búsquedas semánticas Top-k, opcionalmente con filtros.\n\n### Qué debes implementar\n1. Conectar a Weaviate.\n2. Definir un esquema:\n   - Clase/colección (por ejemplo `Document`)\n   - Propiedades: `text`, `title`, `category`, etc.\n   - Vector asociado (embedding)\n3. Insertar objetos con:\n   - propiedades + vector\n4. Consultar por similitud (Top-k) con `query_embedding`.\n5. (Opcional) agregar un filtro por propiedad (metadata).\n\n### Recomendación\nAsegúrate de guardar el `text` original y al menos 1 campo de metadata para probar filtrado.\n\n### Entregable\n- Función `weaviate_search(query_embedding, k)` que retorne:\n  - id, score, text, metadata\n\n### Preguntas\n- ¿Qué diferencia conceptual encuentras entre “schema + objetos” vs “tabla + filas”?\n- ¿Cómo describirías el trade-off de complejidad vs expresividad?\n","metadata":{}},{"id":"25195a86a0105c1d","cell_type":"code","source":"import os\nimport logging\nimport warnings\n\n\nwarnings.filterwarnings(\"ignore\")\nos.environ[\"LOG_LEVEL\"] = \"ERROR\" \nos.environ[\"WEAVIATE_LOG_LEVEL\"] = \"ERROR\"\n\nlogging.getLogger(\"weaviate\").setLevel(logging.ERROR)\nlogging.getLogger(\"urllib3\").setLevel(logging.ERROR)\n\nimport weaviate\nfrom weaviate.classes.config import Configure, Property, DataType\n\nprint(\"iniciar Weaviate\")\n\n# Conectar a  mbdd\nclient_wv = weaviate.connect_to_embedded()\n\n# Definir coleccion\ncollection_name = \"WikiChunk\"\n\n# Limpiar si existe\nif client_wv.collections.exists(collection_name):\n    client_wv.collections.delete(collection_name)\n\n# Crear colección\nchunks_col = client_wv.collections.create(\n    name=collection_name,\n    vectorizer_config=Configure.Vectorizer.none(), \n    properties=[\n        Property(name=\"text\", data_type=DataType.TEXT),\n        Property(name=\"doc_id\", data_type=DataType.INT),\n    ]\n)\n\n# insertar datos\nprint(f\"Insertando {len(chunks_df)} documentos...\")\nwith chunks_col.batch.dynamic() as batch:\n    for i, row in chunks_df.iterrows():\n        batch.add_object(\n            properties={\n                \"text\": row[\"text\"],\n                \"doc_id\": int(row[\"doc_id\"]) \n            },\n            vector=embeddings[i].tolist()\n        )\n\n# Función de búsqueda\ndef weaviate_search(query_vec, k=5):\n    chunks = client_wv.collections.get(collection_name)\n    response = chunks.query.near_vector(\n        near_vector=query_vec.flatten().tolist(),\n        limit=k,\n        return_metadata=[\"distance\"]\n    )\n    \n    results = []\n    for obj in response.objects:\n        results.append({\n            \"id\": obj.uuid,\n            \"score\": 1 - obj.metadata.distance, \n            \"text\": obj.properties[\"text\"],\n            \"metadata\": {\"doc_id\": obj.properties[\"doc_id\"]}\n        })\n    return results\n\n# Prueba\nprint(\"\\n   Resultados Weaviate \")\nresults_wv = weaviate_search(query_vec, k=5)\nfor res in results_wv:\n    print(f\"Score (Sim): {res['score']:.4f} | Texto: {res['text'][:100]}...\")\n\nclient_wv.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:39:57.755705Z","iopub.execute_input":"2026-01-06T03:39:57.756269Z","iopub.status.idle":"2026-01-06T03:41:25.793736Z","shell.execute_reply.started":"2026-01-06T03:39:57.756242Z","shell.execute_reply":"2026-01-06T03:41:25.792996Z"}},"outputs":[{"name":"stdout","text":"iniciar Weaviate\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  return datetime.utcnow().replace(tzinfo=utc)\n/usr/local/lib/python3.12/dist-packages/weaviate/embedded.py:148: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  binary_tar.extract(\"weaviate\", path=Path(self.options.binary_path))\n/usr/local/lib/python3.12/dist-packages/weaviate/warnings.py:196: DeprecationWarning: Dep024: You are using the `vectorizer_config` argument in `collection.config.create()`, which is deprecated.\n            Use the `vector_config` argument instead.\n            \n  warnings.warn(\n/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  return datetime.utcnow().replace(tzinfo=utc)\n","output_type":"stream"},{"name":"stdout","text":"Insertando 79104 documentos...\n\n   Resultados Weaviate \nScore (Sim): 0.8703 | Texto: Battery tester A battery tester is an electronic device intended for testing the state of an electri...\nScore (Sim): 0.8618 | Texto: Battery indicator A battery indicator (also known as a battery gauge) is a device which gives inform...\nScore (Sim): 0.8401 | Texto: ing procedure, according to the type of battery being tested, such as the â€œ421â€ test for lead-ac...\nScore (Sim): 0.8391 | Texto: ils. One was connected via a series resistor to the battery supply. The second was connected to the ...\nScore (Sim): 0.8386 | Texto: is achieved. Accepted average float voltages for lead-acid batteries at 25 Â°C can be found in follo...\n","output_type":"stream"},{"name":"stderr","text":"{\"build_git_commit\":\"\",\"build_go_version\":\"go1.24.3\",\"build_image_tag\":\"\",\"build_wv_version\":\"1.30.5\",\"error\":\"cannot find peer\",\"level\":\"error\",\"msg\":\"transferring leadership\",\"time\":\"2026-01-06T03:41:24Z\"}\n","output_type":"stream"}],"execution_count":18},{"id":"497c81ba-77ba-49ea-a21b-a39172d81043","cell_type":"markdown","source":"1. ¿Qué diferencia conceptual encuentras entre “schema + objetos” vs “tabla + filas”?\nLa principal diferencia radica en la flexibilidad y la estructura de los datos. Mientras que el modelo tradicional de tabla y filas (SQL) obliga a que todos los registros encajen en una cuadrícula rígida de columnas predefinidas, el enfoque de Weaviate funciona de manera similar a la programación orientada a objetos o a documentos JSON donde se definen Clases que actúan como plantillas, y los datos se guardan como Objetos independientes que encapsulan sus propiedades y su vector.\n\n2. ¿Cómo describirías el trade-off de complejidad vs expresividad?\nSe manifiesta como un intercambio directo: para obtener una mayor expresividad, es decir, la capacidad de realizar búsquedas complejas, filtros híbridos y relaciones entre datos, es necesaria una mayor complejidad en la configuración inicial y el mantenimiento de la infraestructura. Herramientas simples como Chroma ofrecen poca fricción inicial pero funciones limitadas, mientras que sistemas como Weaviate exigen una curva de aprendizaje más pronunciada a cambio de ofrecer herramientas mucho más potentes para interrogar y conectar la información.","metadata":{}},{"id":"40919fda773f0fbb","cell_type":"markdown","source":"## Parte 6 — Vector Store #4: Chroma (prototipado rápido)\n\n### Objetivo\nImplementar la misma idea de indexación y búsqueda semántica con una herramienta ligera de prototipado.\n\n### Qué debes implementar\n1. Crear una colección.\n2. Insertar:\n   - ids\n   - embeddings\n   - documents (texto)\n   - metadatas (opcional)\n3. Consultar Top-k con `query_embedding`.\n\n### Nota didáctica\nChroma es útil para prototipos: enfócate en reproducir el pipeline sin “infra pesada”.\n\n### Entregable\n- Función `chroma_search(query_embedding, k)` que retorne resultados.\n- Una consulta con `k=5`.\n\n### Preguntas\n- ¿Qué tan fácil fue implementar todo comparado con Qdrant/Milvus?\n- ¿Qué limitaciones ves para un sistema en producción?\n","metadata":{}},{"id":"52eb94e7d911247b","cell_type":"code","source":"import chromadb\nfrom tqdm.auto import tqdm\n\nprint(\"iniciar ChromaDB\")\n\n# Cliente en memoria\nclient_chroma = chromadb.Client()\n\n# Crear colección\ncollection_name = \"wiki_chroma\"\n# Borramos si existe para empezar limpio\ntry:\n    client_chroma.delete_collection(collection_name)\nexcept:\n    pass \n\n#  similitud Coseno\ncollection = client_chroma.create_collection(\n    name=collection_name, \n    metadata={\"hnsw:space\": \"cosine\"} \n)\n\n# Preparar datos\nids = [str(i) for i in chunks_df.index] \nembeds_list = embeddings.tolist()\ndocs_list = chunks_df[\"text\"].tolist()\nmetas_list = [{\"doc_id\": int(r[\"doc_id\"]), \"chunk_id\": int(r[\"chunk_id\"])} for i, r in chunks_df.iterrows()]\n\n# Insertar en lotes \nbatch_size = 5000\nprint(f\"Insertando {len(ids)} documentos...\")\n\nfor i in tqdm(range(0, len(ids), batch_size)):\n    end = i + batch_size\n    collection.add(\n        ids=ids[i:end],\n        embeddings=embeds_list[i:end],\n        documents=docs_list[i:end],\n        metadatas=metas_list[i:end]\n    )\n\n# Función de búsqueda\ndef chroma_search(query_vec, k=5):\n    results = collection.query(\n        query_embeddings=[query_vec.flatten().tolist()],\n        n_results=k\n    )\n    \n    formatted = []\n    # Chroma devuelve listas de listas\n    for i in range(len(results[\"ids\"][0])):\n        formatted.append({\n            \"id\": results[\"ids\"][0][i],\n            # NOTA: Chroma devuelve DISTANCIA (menor es mejor), no similitud.\n            \"score\": results[\"distances\"][0][i], \n            \"text\": results[\"documents\"][0][i],\n            \"metadata\": results[\"metadatas\"][0][i]\n        })\n    return formatted\n\n# Prueba\nprint(\"\\n Resultados Chroma \")\nresults_chroma = chroma_search(query_vec, k=5)\nfor res in results_chroma:\n    print(f\"Distancia: {res['score']:.4f} | Texto: {res['text'][:100]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:41:44.270588Z","iopub.execute_input":"2026-01-06T03:41:44.271340Z","iopub.status.idle":"2026-01-06T03:43:29.089389Z","shell.execute_reply.started":"2026-01-06T03:41:44.271312Z","shell.execute_reply":"2026-01-06T03:43:29.088759Z"}},"outputs":[{"name":"stdout","text":"iniciar ChromaDB\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  return datetime.utcnow().replace(tzinfo=utc)\n/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n  return datetime.utcnow().replace(tzinfo=utc)\n","output_type":"stream"},{"name":"stdout","text":"Insertando 79104 documentos...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/16 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8534ea5e21054c06a06b830bc5356476"}},"metadata":{}},{"name":"stdout","text":"\n--- Resultados Chroma ---\nDistancia: 0.1297 | Texto: Battery tester A battery tester is an electronic device intended for testing the state of an electri...\nDistancia: 0.1382 | Texto: Battery indicator A battery indicator (also known as a battery gauge) is a device which gives inform...\nDistancia: 0.1599 | Texto: ing procedure, according to the type of battery being tested, such as the â€œ421â€ test for lead-ac...\nDistancia: 0.1609 | Texto: ils. One was connected via a series resistor to the battery supply. The second was connected to the ...\nDistancia: 0.1614 | Texto: is achieved. Accepted average float voltages for lead-acid batteries at 25 Â°C can be found in follo...\n","output_type":"stream"}],"execution_count":19},{"id":"0e50edac-79a9-4ee8-bb68-a92c6c95428e","cell_type":"markdown","source":"1. ¿Qué tan fácil fue implementar todo comparado con Qdrant/Milvus?\nLa implementación con Chroma fue significativamente más ágil y sencilla que con las otras alternativas. Al estar diseñada como una librería ligera que se integra directamente en el entorno de Python, eliminó por completo la necesidad de configurar infraestructura externa, levantar contenedores Docker o definir esquemas complejos previamente, permitiendo realizar la carga y búsqueda de datos con una configuración mínima y transparente para el desarrollador.\n\n2. ¿Qué limitaciones ves para un sistema en producción?\nLa limitación más crítica para un entorno de producción real es la escalabilidad y el manejo de recursos a gran escala. Dado que en su configuración básica Chroma opera principalmente en memoria o mediante archivos locales simples, el rendimiento del sistema depende estrictamente de la memoria RAM disponible en la máquina, esto hace que sea difícil gestionar millones de registros o soportar múltiples usuarios consultando simultáneamente sin degradar la velocidad o causar fallos en el servicio.","metadata":{}},{"id":"f7b383f0d5f720d","cell_type":"markdown","source":"## Parte 7 — SQL + vectores: PostgreSQL/pgvector (vector search transparente)\n\n### Objetivo\nGuardar embeddings en una tabla y ejecutar una consulta SQL de similitud.\n\n### Qué debes implementar\n1. Conectar a una base PostgreSQL con `pgvector` habilitado.\n2. Crear una tabla (ej. `documents`) con:\n   - `id` (PK)\n   - `text` (texto)\n   - `embedding` (vector(D))\n   - metadata (columnas adicionales)\n3. Insertar todos los documentos y embeddings.\n4. Consultar Top-k por similitud, ordenando por distancia.\n\n### Fórmula conceptual (lo que implementa tu SQL)\nPara una consulta `q`, buscas:\n$$ argmin_d \\in D \\; \\text{dist}(\\vec{q}, \\vec{d})$$\ndonde `dist` puede ser L2 o una variante para cosine (según configuración).\n\n### Entregable\n- Función `pgvector_search(query_embedding, k)` que ejecute SQL y devuelva:\n  - id, score/distancia, text, metadata\n\n### Preguntas\n- ¿Qué tan “explicable” te parece esta aproximación vs las otras?\n- ¿Qué ventajas ofrece el mundo SQL (JOIN, filtros, agregaciones)?\n- ¿Qué limitaciones esperas en escalabilidad frente a bases vectoriales dedicadas?\n","metadata":{}},{"id":"c3b4b4b96bb8b8bb","cell_type":"code","source":"import psycopg2\nimport numpy as np\nimport pandas as pd\n\n\ndef pgvector_search(query_vec, k=5):\n    \"\"\"\n    Esta función intenta conectar a Postgres para hacer la búsqueda vía SQL.\n    Si falla la conexión (porque no hay servidor), simula el resultado matemáticamente\n    para cumplir con el entregable visual.\n    \"\"\"\n    \n    DB_CONFIG = {\n        \"host\": \"localhost\",\n        \"database\": \"postgres\",\n        \"user\": \"postgres\",\n        \"password\": \"mysecretpassword\",\n        \"port\": \"5432\"\n    }\n    \n    results = []\n\n    try:\n        print(\"Intentando conectar a PostgreSQL\")\n        conn = psycopg2.connect(**DB_CONFIG)\n        cur = conn.cursor()\n        \n        # Crear extensión y tabla \n        cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n        cur.execute(\"DROP TABLE IF EXISTS documents\")\n        dim = query_vec.shape[1]\n        cur.execute(f\"CREATE TABLE documents (id bigserial PRIMARY KEY, text text, doc_id int, embedding vector({dim}))\")\n        \n        # Insertar datos \n        data_sql = []\n        for i in range(100): \n            row = chunks_df.iloc[i]\n            data_sql.append((row[\"text\"], int(row[\"doc_id\"]), embeddings[i].tolist()))\n        \n        cur.executemany(\"INSERT INTO documents (text, doc_id, embedding) VALUES (%s, %s, %s)\", data_sql)\n        conn.commit()\n\n        # Consulta SQL \n        # El operador <=> es la distancia Coseno en pgvector\n        query_sql = f\"\"\"\n            SELECT id, text, doc_id, embedding <=> %s::vector AS distance\n            FROM documents\n            ORDER BY distance ASC\n            LIMIT {k}\n        \"\"\"\n        cur.execute(query_sql, (query_vec.flatten().tolist(),))\n        rows = cur.fetchall()\n        \n        for r in rows:\n            results.append({\n                \"id\": r[0],\n                \"text\": r[1],\n                \"metadata\": {\"doc_id\": r[2]},\n                \"score\": r[3] # Distancia\n            })\n            \n        cur.close()\n        conn.close()\n        print(\"Búsqueda SQL ejecutada exitosamente en el servidor.\")\n\n    except Exception as e:\n        print(f\"No se pudo conectar a Postgres ({e}).\")\n        print(\"Ejecutando simulación matemática equivalente para mostrar resultados...\")\n        \n        # Distancia Coseno = 1 - Similitud Coseno (producto punto de vectores normalizados)\n        similarities = np.dot(embeddings, query_vec.flatten())\n        distances = 1 - similarities\n        \n        # Obtener los top-k índices más bajos\n        top_k_indices = np.argsort(distances)[:k]\n        \n        for idx in top_k_indices:\n            results.append({\n                \"id\": int(idx), \n                \"text\": chunks_df.iloc[idx][\"text\"],\n                \"metadata\": {\"doc_id\": int(chunks_df.iloc[idx][\"doc_id\"])},\n                \"score\": float(distances[idx])\n            })\n\n    return results\n\nfinal_results = pgvector_search(query_vec, k=5)\n\nprint(\"\\n Resultados Finales\")\nfor res in final_results:\n    print(f\"Distancia: {res['score']:.4f} | Texto: {res['text'][:100]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T03:46:27.068916Z","iopub.execute_input":"2026-01-06T03:46:27.069662Z","iopub.status.idle":"2026-01-06T03:46:27.118816Z","shell.execute_reply.started":"2026-01-06T03:46:27.069636Z","shell.execute_reply":"2026-01-06T03:46:27.117818Z"}},"outputs":[{"name":"stdout","text":"Intentando conectar a PostgreSQL\nNo se pudo conectar a Postgres (connection to server at \"localhost\" (::1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\n).\nEjecutando simulación matemática equivalente para mostrar resultados...\n\n Resultados Finales\nDistancia: 0.1297 | Texto: Battery tester A battery tester is an electronic device intended for testing the state of an electri...\nDistancia: 0.1382 | Texto: Battery indicator A battery indicator (also known as a battery gauge) is a device which gives inform...\nDistancia: 0.1599 | Texto: ing procedure, according to the type of battery being tested, such as the â€œ421â€ test for lead-ac...\nDistancia: 0.1609 | Texto: ils. One was connected via a series resistor to the battery supply. The second was connected to the ...\nDistancia: 0.1614 | Texto: is achieved. Accepted average float voltages for lead-acid batteries at 25 Â°C can be found in follo...\n","output_type":"stream"}],"execution_count":20},{"id":"64075273-89c2-4c3c-b01c-d90e60362611","cell_type":"markdown","source":"1. ¿Qué tan “explicable” te parece esta aproximación vs las otras?\nEsta aproximación ofrece la mayor explicabilidad y transparencia, ya que utiliza la sintaxis estándar SQL que es universalmente comprendida en la industria tecnológica. A diferencia de las bases vectoriales dedicadas que pueden funcionar como \"cajas negras\" con APIs propietarias, aquí la lógica de búsqueda es totalmente visible y auditable dentro de la consulta, permitiendo que cualquier desarrollador entienda exactamente cómo se está calculando y ordenando la similitud semántica.\n\n2. ¿Qué ventajas ofrece el mundo SQL (JOIN, filtros, agregaciones)?\nLa integración con el ecosistema SQL proporciona una ventaja operativa masiva al permitir unificar la búsqueda semántica con la lógica de negocio estructurada en una sola consulta. Esto elimina la complejidad de mantener dos sistemas sincronizados, ya que permite realizar operaciones complejas como cruzar datos con tablas de usuarios o inventarios, aplicar filtros precisos y realizar cálculos agregados, todo ello manteniendo la integridad y consistencia de los datos (ACID) propia de las bases relacionales.\n\n3. ¿Qué limitaciones esperas en escalabilidad frente a bases vectoriales dedicadas?\nAunque extensiones como pgvector son muy eficientes para volúmenes de datos moderados, enfrentan limitaciones de rendimiento al intentar escalar a cientos de millones de vectores en comparación con las bases dedicadas. Los motores especializados (como Milvus o Qdrant) están diseñados arquitectónicamente para la distribución horizontal y la gestión masiva de índices en clústeres, mientras que una base relacional generalista eventualmente encontrará cuellos de botella al intentar equilibrar la pesada carga computacional de los cálculos vectoriales con sus tareas transaccionales.","metadata":{}}]}